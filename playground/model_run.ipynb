{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T10:50:52.237959Z",
     "start_time": "2025-10-01T10:50:51.383936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from src.model.model import MusicTransformer\n",
    "from pathlib import Path\n",
    "\n",
    "from src.utils.data.guitar_dataset import GuitarDataset\n",
    "from src.utils.data.random_guitar_seq_dataset import RandomGuitarSeqDataset\n",
    "from src.utils.hyperparameters import BATCH_SIZE, BLOCK_SIZE, EMBEDDING_DIM, N_LAYER, N_HEAD, DROPOUT, VOCAB_SIZE, \\\n",
    "    LEARNING_RATE"
   ],
   "id": "c487a78f87afdb64",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T10:50:53.871670Z",
     "start_time": "2025-10-01T10:50:53.868900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_root = Path(\"../data/\")\n",
    "midi_folder = data_root / \"midi/\"\n",
    "augmented_folder = data_root / \"augmented/\"\n",
    "tokenized_folder = data_root / \"tokenized/\"\n",
    "splits_folder = data_root / \"splits/\"\n",
    "train_tok_folder = tokenized_folder / \"train-aug/\"\n",
    "val_tok_folder = tokenized_folder / \"val/\"\n",
    "train_midi_folder = data_root / \"train-midi/\"\n",
    "val_midi_folder = data_root / \"val-midi/\""
   ],
   "id": "e6ecb80d56c07e23",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T10:50:58.566562Z",
     "start_time": "2025-10-01T10:50:58.564300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# hyper-parameters\n",
    "batch_size = BATCH_SIZE\n",
    "\n",
    "block_size = BLOCK_SIZE\n",
    "n_embd = EMBEDDING_DIM\n",
    "vocab_size = VOCAB_SIZE\n",
    "n_layer = N_LAYER\n",
    "n_head = N_HEAD\n",
    "dropout = DROPOUT\n",
    "\n",
    "learning_rate = LEARNING_RATE\n",
    "training_split = 0.8"
   ],
   "id": "d0fd759dece2cc7e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T10:51:00.462869Z",
     "start_time": "2025-10-01T10:51:00.445190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# setting the device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ],
   "id": "d313176f924b1e79",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T10:51:02.042561Z",
     "start_time": "2025-10-01T10:51:02.040706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# AMP setup, works only on CUDA\n",
    "use_amp = (device == \"cuda\")\n",
    "if use_amp and hasattr(torch.cuda, \"is_bf16_supported\") and torch.cuda.is_bf16_supported():\n",
    "    amp_dtype = torch.bfloat16\n",
    "else:\n",
    "    amp_dtype = torch.float16\n",
    "\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=use_amp)"
   ],
   "id": "d4cf2e30dd1e49ce",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T10:51:41.209577Z",
     "start_time": "2025-10-01T10:51:41.117589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# prepare datasets\n",
    "train_files = sorted(train_tok_folder.glob(\"*.json\"))\n",
    "val_files = sorted(val_tok_folder.glob(\"*.json\"))\n",
    "random.shuffle(train_files)\n",
    "\n",
    "train_ds = GuitarDataset(block_size=block_size, stride=block_size // 2, file_list=train_files)\n",
    "val_ds = GuitarDataset(block_size=block_size, stride=block_size // 2, file_list=val_files)\n",
    "# train_ds = RandomGuitarSeqDataset(block_size=block_size, epoch_len=2000, file_list=all_files[:split])\n",
    "# val_ds = RandomGuitarSeqDataset(block_size=block_size,  epoch_len=400, file_list=all_files[split:])"
   ],
   "id": "4e085618437ba1ad",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T10:51:44.642085Z",
     "start_time": "2025-10-01T10:51:44.639426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, drop_last=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=32, shuffle=True, drop_last=True)"
   ],
   "id": "539692115b123607",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T10:51:46.074960Z",
     "start_time": "2025-10-01T10:51:46.072732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Training tokens count\", train_dl.dataset.tokens)\n",
    "print(\"Validation tokens count\", val_dl.dataset.tokens)"
   ],
   "id": "776c5472bebd0228",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens count 574897\n",
      "Validation tokens count 27587\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T10:51:57.330944Z",
     "start_time": "2025-10-01T10:51:57.225954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = MusicTransformer(\n",
    "    vocab_size=vocab_size,\n",
    "    n_embd=n_embd,\n",
    "    n_head=n_head,\n",
    "    n_layer=n_layer,\n",
    "    block_size=block_size,\n",
    "    dropout=dropout\n",
    ").to(device)"
   ],
   "id": "8818a8d2bd225435",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T10:52:01.733177Z",
     "start_time": "2025-10-01T10:52:00.821971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# using AdamW optimisation\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, betas=(0.9, 0.95), weight_decay=0.1)"
   ],
   "id": "c3eb0eca5ba98d83",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T10:52:03.116768Z",
     "start_time": "2025-10-01T10:52:03.114744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Parameter count: \", sum([p.numel() for p in model.parameters()]))\n",
    "print(\"Training on \", device)\n",
    "print(\"Using amp?\", use_amp)"
   ],
   "id": "e69095cfa2232d0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter count:  4728248\n",
      "Training on  mps\n",
      "Using amp? False\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T10:52:05.470574Z",
     "start_time": "2025-10-01T10:52:05.468855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from src.model.model import Head\n",
    "# import numpy as np\n",
    "# x_test, y_test = train_ds.__getitem__(56)\n",
    "# x_test, y_test = x_test.view(1,-1).to(device), y_test.view(1,-1).to(device)\n",
    "#\n",
    "print(-np.log(1/8000))\n",
    "#\n",
    "# logits, loss = model(x_test, y_test)\n",
    "# loss"
   ],
   "id": "781977d0ce522c2e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.987196820661973\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T10:58:44.579426Z",
     "start_time": "2025-10-01T10:52:08.340912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 20\n",
    "V = vocab_size\n",
    "lnV = np.log(V)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ---- train -----\n",
    "    model.train()\n",
    "    for x, y in train_dl:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # using torch.autocast here with device_type to avoid backend-specific contexts\n",
    "        with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
    "            logits, loss = model(x, y)\n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "    # ----- validate -----\n",
    "    model.eval()\n",
    "    val_loss, total_tokens = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_dl:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            _, l = model(x, y) # loss here is already mean loss per token for this batch\n",
    "            # as we have already reshaped logits in forward when computing loss against targets\n",
    "            num_tokens = y.numel()\n",
    "            val_loss += l.item() * num_tokens\n",
    "            total_tokens += num_tokens\n",
    "\n",
    "    avg_loss = val_loss / total_tokens\n",
    "    ppl = np.exp(avg_loss)\n",
    "    bpc = avg_loss / np.log(2)\n",
    "    improv_ratio = V / ppl\n",
    "    delta_nats = lnV - avg_loss\n",
    "\n",
    "    print(\n",
    "        f\"epoch {epoch:03d} \"\n",
    "        f\"train {loss.item():.4f} \"\n",
    "        f\"val_loss {avg_loss:.4f}  ppl {ppl:.0f}  \"\n",
    "        f\"bpc {bpc:.3f}  Δnats {delta_nats:.3f}  x-better {improv_ratio:.2f}x  (lnV {lnV:.3f})\"\n",
    "    )"
   ],
   "id": "96a0a357ebe63e92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 000 train 5.9336 val_loss 5.9081  ppl 368  bpc 8.524  Δnats 2.098  x-better 8.15x  (lnV 8.006)\n",
      "epoch 001 train 4.2858 val_loss 4.7746  ppl 118  bpc 6.888  Δnats 3.232  x-better 25.33x  (lnV 8.006)\n",
      "epoch 002 train 3.5772 val_loss 4.3915  ppl 81  bpc 6.336  Δnats 3.615  x-better 37.15x  (lnV 8.006)\n",
      "epoch 003 train 3.2622 val_loss 4.2553  ppl 70  bpc 6.139  Δnats 3.751  x-better 42.57x  (lnV 8.006)\n",
      "epoch 004 train 2.9729 val_loss 4.2022  ppl 67  bpc 6.062  Δnats 3.804  x-better 44.89x  (lnV 8.006)\n",
      "epoch 005 train 2.6844 val_loss 4.2039  ppl 67  bpc 6.065  Δnats 3.802  x-better 44.81x  (lnV 8.006)\n",
      "epoch 006 train 2.3972 val_loss 4.1577  ppl 64  bpc 5.998  Δnats 3.849  x-better 46.93x  (lnV 8.006)\n",
      "epoch 007 train 2.2595 val_loss 4.2136  ppl 68  bpc 6.079  Δnats 3.793  x-better 44.38x  (lnV 8.006)\n",
      "epoch 008 train 2.0058 val_loss 4.2436  ppl 70  bpc 6.122  Δnats 3.763  x-better 43.07x  (lnV 8.006)\n",
      "epoch 009 train 1.9471 val_loss 4.2818  ppl 72  bpc 6.177  Δnats 3.725  x-better 41.45x  (lnV 8.006)\n",
      "epoch 010 train 1.7911 val_loss 4.3048  ppl 74  bpc 6.211  Δnats 3.702  x-better 40.51x  (lnV 8.006)\n",
      "epoch 011 train 1.6321 val_loss 4.3655  ppl 79  bpc 6.298  Δnats 3.641  x-better 38.13x  (lnV 8.006)\n",
      "epoch 012 train 1.4695 val_loss 4.4114  ppl 82  bpc 6.364  Δnats 3.595  x-better 36.41x  (lnV 8.006)\n",
      "epoch 013 train 1.6105 val_loss 4.4634  ppl 87  bpc 6.439  Δnats 3.543  x-better 34.57x  (lnV 8.006)\n",
      "epoch 014 train 1.4220 val_loss 4.5287  ppl 93  bpc 6.534  Δnats 3.478  x-better 32.38x  (lnV 8.006)\n",
      "epoch 015 train 1.5173 val_loss 4.5694  ppl 96  bpc 6.592  Δnats 3.437  x-better 31.09x  (lnV 8.006)\n",
      "epoch 016 train 1.3711 val_loss 4.6282  ppl 102  bpc 6.677  Δnats 3.378  x-better 29.32x  (lnV 8.006)\n",
      "epoch 017 train 1.3396 val_loss 4.6836  ppl 108  bpc 6.757  Δnats 3.323  x-better 27.74x  (lnV 8.006)\n",
      "epoch 018 train 1.1755 val_loss 4.7620  ppl 117  bpc 6.870  Δnats 3.244  x-better 25.64x  (lnV 8.006)\n",
      "epoch 019 train 1.0921 val_loss 4.7812  ppl 119  bpc 6.898  Δnats 3.225  x-better 25.16x  (lnV 8.006)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T12:07:01.667328Z",
     "start_time": "2025-10-01T12:06:39.601177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x, y = val_dl.dataset.__getitem__(15)\n",
    "temp = x[:500]\n",
    "out = model.generate(temp.view(1, -1).to(device), max_new_tokens=2500).cpu()\n",
    "out"
   ],
   "id": "f36966a10273d2cf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[529,  26, 518,  ..., 490, 995, 490]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T12:07:05.705395Z",
     "start_time": "2025-10-01T12:07:05.690142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from miditok import REMI, TokenizerConfig\n",
    "\n",
    "tokenizer = REMI(params=Path(\"../data/tokenized/config/tokenizer.json\"))\n",
    "print(\"Is trained\", tokenizer.is_trained)\n",
    "out_midi = tokenizer.decode(out[0])\n",
    "temp_midi = tokenizer.decode(temp)"
   ],
   "id": "ce320f193e50a6e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is trained True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/music-llm/lib/python3.12/site-packages/miditok/tokenizations/remi.py:88: UserWarning: Attribute controls are not compatible with 'config.one_token_stream_for_programs' and multi-vocabulary tokenizers. Disabling them from the config.\n",
      "  super().__init__(tokenizer_config, params)\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T12:07:08.617791Z",
     "start_time": "2025-10-01T12:07:08.613320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out_midi.dump_midi(data_root / \"output\" / \"test_gen.mid\")\n",
    "temp_midi.dump_midi(data_root / \"output\" / \"input_input.mid\")"
   ],
   "id": "5427de0cbbfbc765",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d33f2e482dd4afe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
