{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:46:54.809720Z",
     "start_time": "2025-09-16T17:46:54.227442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from src.model.model import MusicTransformer\n",
    "from pathlib import Path\n",
    "\n",
    "from src.utils.data.guitar_dataset import GuitarDataset\n",
    "from src.utils.data.random_guitar_seq_dataset import RandomGuitarSeqDataset\n",
    "from src.utils.hyperparameters import BATCH_SIZE, BLOCK_SIZE, EMBEDDING_DIM, N_LAYER, N_HEAD, DROPOUT, VOCAB_SIZE, \\\n",
    "    LEARNING_RATE"
   ],
   "id": "c487a78f87afdb64",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:46:54.813340Z",
     "start_time": "2025-09-16T17:46:54.812009Z"
    }
   },
   "cell_type": "code",
   "source": "tokenized_folder = Path(\"../data/tokenized/\")",
   "id": "e6ecb80d56c07e23",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:46:54.872551Z",
     "start_time": "2025-09-16T17:46:54.870942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# hyper-parameters\n",
    "batch_size = BATCH_SIZE\n",
    "\n",
    "block_size = BLOCK_SIZE\n",
    "n_embd = EMBEDDING_DIM\n",
    "vocab_size = VOCAB_SIZE\n",
    "n_layer = N_LAYER\n",
    "n_head = N_HEAD\n",
    "dropout = DROPOUT\n",
    "\n",
    "learning_rate = LEARNING_RATE\n",
    "training_split = 0.8"
   ],
   "id": "d0fd759dece2cc7e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:46:54.887259Z",
     "start_time": "2025-09-16T17:46:54.875585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# setting the device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ],
   "id": "d313176f924b1e79",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:46:54.892030Z",
     "start_time": "2025-09-16T17:46:54.890336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# AMP setup, works only on CUDA\n",
    "use_amp = (device == \"cuda\")\n",
    "if use_amp and hasattr(torch.cuda, \"is_bf16_supported\") and torch.cuda.is_bf16_supported():\n",
    "    amp_dtype = torch.bfloat16\n",
    "else:\n",
    "    amp_dtype = torch.float16\n",
    "\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=use_amp)"
   ],
   "id": "d4cf2e30dd1e49ce",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:46:54.904591Z",
     "start_time": "2025-09-16T17:46:54.895338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# prepare datasets\n",
    "all_files = sorted(tokenized_folder.glob(\"*.json\"))\n",
    "random.shuffle(all_files)\n",
    "\n",
    "split = int(training_split * len(all_files))\n",
    "# train_ds = GuitarDataset(block_size=block_size, stride=block_size // 2, file_list=all_files[:split])\n",
    "# val_ds = GuitarDataset(block_size=block_size, stride=block_size // 2, file_list=all_files[split:])\n",
    "train_ds = RandomGuitarSeqDataset(block_size=block_size, epoch_len=2000, file_list=all_files[:split])\n",
    "val_ds = RandomGuitarSeqDataset(block_size=block_size,  epoch_len=400, file_list=all_files[split:])"
   ],
   "id": "4e085618437ba1ad",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:46:54.909452Z",
     "start_time": "2025-09-16T17:46:54.908021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, drop_last=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=32, shuffle=True, drop_last=True)"
   ],
   "id": "539692115b123607",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:46:54.913927Z",
     "start_time": "2025-09-16T17:46:54.912737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print(\"Training tokens count\", train_dl.dataset.tokens)\n",
    "# print(\"Validation tokens count\", val_dl.dataset.tokens)"
   ],
   "id": "776c5472bebd0228",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:46:54.968096Z",
     "start_time": "2025-09-16T17:46:54.921025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = MusicTransformer(\n",
    "    vocab_size=vocab_size,\n",
    "    n_embd=n_embd,\n",
    "    n_head=n_head,\n",
    "    n_layer=n_layer,\n",
    "    block_size=block_size,\n",
    "    dropout=dropout\n",
    ").to(device)"
   ],
   "id": "8818a8d2bd225435",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:46:55.511718Z",
     "start_time": "2025-09-16T17:46:54.970264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# using AdamW optimisation\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, betas=(0.9, 0.95), weight_decay=0.1)"
   ],
   "id": "c3eb0eca5ba98d83",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:46:55.517735Z",
     "start_time": "2025-09-16T17:46:55.515987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Parameter count: \", sum([p.numel() for p in model.parameters()]))\n",
    "print(\"Training on \", device)\n",
    "print(\"Using amp?\", use_amp)"
   ],
   "id": "e69095cfa2232d0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter count:  7293248\n",
      "Training on  mps\n",
      "Using amp? False\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:46:55.526739Z",
     "start_time": "2025-09-16T17:46:55.525248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from src.model.model import Head\n",
    "# import numpy as np\n",
    "# x_test, y_test = train_ds.__getitem__(56)\n",
    "# x_test, y_test = x_test.view(1,-1).to(device), y_test.view(1,-1).to(device)\n",
    "#\n",
    "print(-np.log(1/8000))\n",
    "#\n",
    "# logits, loss = model(x_test, y_test)\n",
    "# loss"
   ],
   "id": "781977d0ce522c2e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.987196820661973\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:49:19.244925Z",
     "start_time": "2025-09-16T17:46:55.532915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 40\n",
    "V = vocab_size\n",
    "lnV = np.log(V)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ---- train -----\n",
    "    model.train()\n",
    "    for x, y in train_dl:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # using torch.autocast here with device_type to avoid backend-specific contexts\n",
    "        with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
    "            logits, loss = model(x, y)\n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "    # ----- validate -----\n",
    "    model.eval()\n",
    "    val_loss, total_tokens = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_dl:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            _, l = model(x, y) # loss here is already mean loss per token for this batch\n",
    "            # as we have already reshaped logits in forward when computing loss against targets\n",
    "            num_tokens = y.numel()\n",
    "            val_loss += l.item() * num_tokens\n",
    "            total_tokens += num_tokens\n",
    "\n",
    "    avg_loss = val_loss / total_tokens\n",
    "    ppl = np.exp(avg_loss)\n",
    "    bpc = avg_loss / np.log(2)\n",
    "    improv_ratio = V / ppl\n",
    "    delta_nats = lnV - avg_loss\n",
    "\n",
    "    print(\n",
    "        f\"epoch {epoch:03d} \"\n",
    "        f\"train {loss.item():.4f} \"\n",
    "        f\"val_loss {avg_loss:.4f}  ppl {ppl:.0f}  \"\n",
    "        f\"bpc {bpc:.3f}  Δnats {delta_nats:.3f}  x-better {improv_ratio:.2f}x  (lnV {lnV:.3f})\"\n",
    "    )"
   ],
   "id": "96a0a357ebe63e92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 000 train 7.9561 val_loss 9.1026  ppl 8978  bpc 13.132  Δnats -0.115  x-better 0.89x  (lnV 8.987)\n",
      "epoch 001 train 7.6018 val_loss 9.1376  ppl 9298  bpc 13.183  Δnats -0.150  x-better 0.86x  (lnV 8.987)\n",
      "epoch 002 train 6.8865 val_loss 9.1855  ppl 9754  bpc 13.252  Δnats -0.198  x-better 0.82x  (lnV 8.987)\n",
      "epoch 003 train 6.1408 val_loss 9.1731  ppl 9634  bpc 13.234  Δnats -0.186  x-better 0.83x  (lnV 8.987)\n",
      "epoch 004 train 5.4834 val_loss 9.2285  ppl 10184  bpc 13.314  Δnats -0.241  x-better 0.79x  (lnV 8.987)\n",
      "epoch 005 train 5.0255 val_loss 9.3243  ppl 11207  bpc 13.452  Δnats -0.337  x-better 0.71x  (lnV 8.987)\n",
      "epoch 006 train 4.5168 val_loss 9.4745  ppl 13024  bpc 13.669  Δnats -0.487  x-better 0.61x  (lnV 8.987)\n",
      "epoch 007 train 3.7018 val_loss 9.3794  ppl 11842  bpc 13.532  Δnats -0.392  x-better 0.68x  (lnV 8.987)\n",
      "epoch 008 train 3.5143 val_loss 9.6543  ppl 15588  bpc 13.928  Δnats -0.667  x-better 0.51x  (lnV 8.987)\n",
      "epoch 009 train 3.1369 val_loss 9.6365  ppl 15314  bpc 13.903  Δnats -0.649  x-better 0.52x  (lnV 8.987)\n",
      "epoch 010 train 2.6751 val_loss 9.6706  ppl 15845  bpc 13.952  Δnats -0.683  x-better 0.50x  (lnV 8.987)\n",
      "epoch 011 train 2.5065 val_loss 9.8642  ppl 19229  bpc 14.231  Δnats -0.877  x-better 0.42x  (lnV 8.987)\n",
      "epoch 012 train 2.3046 val_loss 9.7770  ppl 17624  bpc 14.105  Δnats -0.790  x-better 0.45x  (lnV 8.987)\n",
      "epoch 013 train 1.8625 val_loss 10.0172  ppl 22408  bpc 14.452  Δnats -1.030  x-better 0.36x  (lnV 8.987)\n",
      "epoch 014 train 1.7282 val_loss 10.1591  ppl 25825  bpc 14.656  Δnats -1.172  x-better 0.31x  (lnV 8.987)\n",
      "epoch 015 train 1.9859 val_loss 10.2308  ppl 27746  bpc 14.760  Δnats -1.244  x-better 0.29x  (lnV 8.987)\n",
      "epoch 016 train 1.5944 val_loss 10.3302  ppl 30643  bpc 14.903  Δnats -1.343  x-better 0.26x  (lnV 8.987)\n",
      "epoch 017 train 1.5226 val_loss 10.4317  ppl 33919  bpc 15.050  Δnats -1.445  x-better 0.24x  (lnV 8.987)\n",
      "epoch 018 train 1.2708 val_loss 10.5357  ppl 37637  bpc 15.200  Δnats -1.549  x-better 0.21x  (lnV 8.987)\n",
      "epoch 019 train 1.3340 val_loss 10.5970  ppl 40015  bpc 15.288  Δnats -1.610  x-better 0.20x  (lnV 8.987)\n",
      "epoch 020 train 1.1909 val_loss 10.6527  ppl 42307  bpc 15.369  Δnats -1.666  x-better 0.19x  (lnV 8.987)\n",
      "epoch 021 train 1.0774 val_loss 10.7308  ppl 45742  bpc 15.481  Δnats -1.744  x-better 0.17x  (lnV 8.987)\n",
      "epoch 022 train 1.0288 val_loss 10.9245  ppl 55522  bpc 15.761  Δnats -1.937  x-better 0.14x  (lnV 8.987)\n",
      "epoch 023 train 0.9899 val_loss 10.8985  ppl 54096  bpc 15.723  Δnats -1.911  x-better 0.15x  (lnV 8.987)\n",
      "epoch 024 train 0.8314 val_loss 11.2337  ppl 75635  bpc 16.207  Δnats -2.246  x-better 0.11x  (lnV 8.987)\n",
      "epoch 025 train 0.7407 val_loss 11.0100  ppl 60479  bpc 15.884  Δnats -2.023  x-better 0.13x  (lnV 8.987)\n",
      "epoch 026 train 0.7620 val_loss 11.2399  ppl 76107  bpc 16.216  Δnats -2.253  x-better 0.11x  (lnV 8.987)\n",
      "epoch 027 train 0.7070 val_loss 11.3487  ppl 84854  bpc 16.373  Δnats -2.361  x-better 0.09x  (lnV 8.987)\n",
      "epoch 028 train 0.5463 val_loss 11.3011  ppl 80914  bpc 16.304  Δnats -2.314  x-better 0.10x  (lnV 8.987)\n",
      "epoch 029 train 0.5437 val_loss 11.3887  ppl 88319  bpc 16.430  Δnats -2.402  x-better 0.09x  (lnV 8.987)\n",
      "epoch 030 train 0.6021 val_loss 11.5529  ppl 104082  bpc 16.667  Δnats -2.566  x-better 0.08x  (lnV 8.987)\n",
      "epoch 031 train 0.6172 val_loss 11.6769  ppl 117819  bpc 16.846  Δnats -2.690  x-better 0.07x  (lnV 8.987)\n",
      "epoch 032 train 0.5385 val_loss 11.6416  ppl 113736  bpc 16.795  Δnats -2.654  x-better 0.07x  (lnV 8.987)\n",
      "epoch 033 train 0.4752 val_loss 11.8075  ppl 134252  bpc 17.035  Δnats -2.820  x-better 0.06x  (lnV 8.987)\n",
      "epoch 034 train 0.4734 val_loss 11.7318  ppl 124472  bpc 16.925  Δnats -2.745  x-better 0.06x  (lnV 8.987)\n",
      "epoch 035 train 0.4157 val_loss 11.7955  ppl 132651  bpc 17.017  Δnats -2.808  x-better 0.06x  (lnV 8.987)\n",
      "epoch 036 train 0.4084 val_loss 12.0896  ppl 178016  bpc 17.442  Δnats -3.102  x-better 0.04x  (lnV 8.987)\n",
      "epoch 037 train 0.4297 val_loss 12.1189  ppl 183300  bpc 17.484  Δnats -3.132  x-better 0.04x  (lnV 8.987)\n",
      "epoch 038 train 0.3793 val_loss 12.0703  ppl 174611  bpc 17.414  Δnats -3.083  x-better 0.05x  (lnV 8.987)\n",
      "epoch 039 train 0.3473 val_loss 12.1584  ppl 190693  bpc 17.541  Δnats -3.171  x-better 0.04x  (lnV 8.987)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:49:22.238985Z",
     "start_time": "2025-09-16T17:49:19.373186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x, y = val_dl.dataset.__getitem__(5)\n",
    "temp = x[:50]\n",
    "out = model.generate(temp.view(1, -1).to(device), max_new_tokens=100).cpu()\n",
    "out"
   ],
   "id": "f36966a10273d2cf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 136,  547,   54, 1106, 4609,  462,   54,  837, 5595,  456, 2380, 6773,\n",
       "         1698,  518,  515, 6724,   68, 2852,   54, 1308, 4827,   65,  778, 4827,\n",
       "         5117,  453, 2898, 7404,   66,  907,  456,  601,  130, 4454,  818, 7388,\n",
       "           66,  100, 6805, 3624, 2821,  500, 5304, 3180, 1352, 7759,   47, 1352,\n",
       "           66, 7894,  658,  456, 5075, 1640,  463, 7056, 3498, 6155, 1644,  515,\n",
       "         5048,  626,  459,   64, 1916, 7857, 2390,  649,  641,   59, 4541,   67,\n",
       "          598,  460, 3726,  178, 5831,  176, 1072,  988,  189,  465,   62,  951,\n",
       "         4315, 6281,   43, 4099,  950,  513,   50,  504,  493,   58, 2752, 7246,\n",
       "          520, 6768,   41, 1645,  503,   61, 2040,   60, 1271,   62, 5794, 1086,\n",
       "           41, 2046, 2057,   55,  918,  501, 4058,  509,   62, 4195, 2203,   46,\n",
       "          936,   57, 7006,  691,   65,  478,   50, 1039,  501,   60, 1311,   55,\n",
       "         4708,  493,   60, 1109, 1689,  520,   60, 1013, 5626, 2854, 4160, 6634,\n",
       "         3526,  493, 4064,  503,   60, 1013]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:49:22.470855Z",
     "start_time": "2025-09-16T17:49:22.469375Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ce320f193e50a6e5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
