{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T17:33:21.790920Z",
     "start_time": "2025-10-21T17:33:21.238299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from src.model.model import MusicTransformer\n",
    "from pathlib import Path\n",
    "\n",
    "from src.utils.data.guitar_dataset import GuitarDataset\n",
    "from src.utils.data.random_guitar_seq_dataset import RandomGuitarSeqDataset\n",
    "from src.utils.hyperparameters import BATCH_SIZE, BLOCK_SIZE, EMBEDDING_DIM, N_LAYER, N_HEAD, DROPOUT, VOCAB_SIZE, \\\n",
    "    LEARNING_RATE"
   ],
   "id": "c487a78f87afdb64",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T17:33:21.809125Z",
     "start_time": "2025-10-21T17:33:21.807580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_root = Path(\"../data/\")\n",
    "midi_folder = data_root / \"midi/\"\n",
    "augmented_folder = data_root / \"augmented/\"\n",
    "tokenized_folder = data_root / \"tokenized/\"\n",
    "splits_folder = data_root / \"splits/\"\n",
    "train_tok_folder = tokenized_folder / \"train-aug/\"\n",
    "val_tok_folder = tokenized_folder / \"val/\"\n",
    "train_midi_folder = data_root / \"train-midi/\"\n",
    "val_midi_folder = data_root / \"val-midi/\""
   ],
   "id": "e6ecb80d56c07e23",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T17:33:21.856182Z",
     "start_time": "2025-10-21T17:33:21.854581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# hyper-parameters\n",
    "batch_size = BATCH_SIZE\n",
    "\n",
    "block_size = BLOCK_SIZE\n",
    "n_embd = EMBEDDING_DIM\n",
    "vocab_size = VOCAB_SIZE\n",
    "n_layer = N_LAYER\n",
    "n_head = N_HEAD\n",
    "dropout = DROPOUT\n",
    "\n",
    "learning_rate = LEARNING_RATE\n",
    "training_split = 0.8"
   ],
   "id": "d0fd759dece2cc7e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T17:33:22.029954Z",
     "start_time": "2025-10-21T17:33:21.862456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# setting the device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ],
   "id": "d313176f924b1e79",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T17:33:22.078795Z",
     "start_time": "2025-10-21T17:33:22.077073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# AMP setup, works only on CUDA\n",
    "use_amp = (device == \"cuda\")\n",
    "if use_amp and hasattr(torch.cuda, \"is_bf16_supported\") and torch.cuda.is_bf16_supported():\n",
    "    amp_dtype = torch.bfloat16\n",
    "else:\n",
    "    amp_dtype = torch.float16\n",
    "\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=use_amp)"
   ],
   "id": "d4cf2e30dd1e49ce",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T17:33:22.127528Z",
     "start_time": "2025-10-21T17:33:22.125501Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Using device\", device)",
   "id": "1a2558d82cc0a417",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T17:33:22.151214Z",
     "start_time": "2025-10-21T17:33:22.133953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# prepare datasets\n",
    "train_files = sorted(train_tok_folder.glob(\"*.json\"))\n",
    "val_files = sorted(val_tok_folder.glob(\"*.json\"))\n",
    "random.shuffle(train_files)\n",
    "\n",
    "# train_ds = GuitarDataset(block_size=block_size, stride=block_size // 2, file_list=train_files)\n",
    "# val_ds = GuitarDataset(block_size=block_size, stride=block_size // 2, file_list=val_files)\n",
    "train_ds = RandomGuitarSeqDataset(block_size=block_size, epoch_len=2000, file_list=train_files)\n",
    "val_ds = RandomGuitarSeqDataset(block_size=block_size,  epoch_len=400, file_list=val_files)"
   ],
   "id": "4e085618437ba1ad",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T17:33:22.182668Z",
     "start_time": "2025-10-21T17:33:22.181194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, drop_last=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=32, shuffle=True, drop_last=True)"
   ],
   "id": "539692115b123607",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T17:33:23.669024Z",
     "start_time": "2025-10-21T17:33:23.666952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Training tokens count\", train_dl.dataset.total_tokens)\n",
    "print(\"Validation tokens count\", val_dl.dataset.total_tokens)"
   ],
   "id": "776c5472bebd0228",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens count 470450\n",
      "Validation tokens count 56855\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T17:33:26.435440Z",
     "start_time": "2025-10-21T17:33:26.214831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = MusicTransformer(\n",
    "    vocab_size=vocab_size,\n",
    "    n_embd=n_embd,\n",
    "    n_head=n_head,\n",
    "    n_layer=n_layer,\n",
    "    block_size=block_size,\n",
    "    dropout=dropout\n",
    ").to(device)"
   ],
   "id": "8818a8d2bd225435",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T17:33:27.957193Z",
     "start_time": "2025-10-21T17:33:27.591749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# using AdamW optimisation\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, betas=(0.9, 0.95), weight_decay=0.1)"
   ],
   "id": "c3eb0eca5ba98d83",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T17:33:29.232993Z",
     "start_time": "2025-10-21T17:33:29.229950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Parameter count: \", sum([p.numel() for p in model.parameters()]))\n",
    "print(\"Training on \", device)\n",
    "print(\"Using amp?\", use_amp)"
   ],
   "id": "e69095cfa2232d0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter count:  30877368\n",
      "Training on  cuda\n",
      "Using amp? False\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T17:33:43.534414Z",
     "start_time": "2025-10-21T17:33:43.531198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from src.model.model import Head\n",
    "# import numpy as np\n",
    "# x_test, y_test = train_ds.__getitem__(56)\n",
    "# x_test, y_test = x_test.view(1,-1).to(device), y_test.view(1,-1).to(device)\n",
    "#\n",
    "print(-np.log(1/8000))\n",
    "device\n",
    "#\n",
    "# logits, loss = model(x_test, y_test)\n",
    "# loss"
   ],
   "id": "781977d0ce522c2e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.987196820661973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T17:33:46.421708Z",
     "start_time": "2025-10-21T17:33:45.778407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 20\n",
    "V = vocab_size\n",
    "lnV = np.log(V)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ---- train -----\n",
    "    model.train()\n",
    "    for x, y in train_dl:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # using torch.autocast here with device_type to avoid backend-specific contexts\n",
    "        with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
    "            logits, loss = model(x, y)\n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "    # ----- validate -----\n",
    "    model.eval()\n",
    "    val_loss, total_tokens = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_dl:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            _, l = model(x, y) # loss here is already mean loss per token for this batch\n",
    "            # as we have already reshaped logits in forward when computing loss against targets\n",
    "            num_tokens = y.numel()\n",
    "            val_loss += l.item() * num_tokens\n",
    "            total_tokens += num_tokens\n",
    "\n",
    "    avg_loss = val_loss / total_tokens\n",
    "    ppl = np.exp(avg_loss)\n",
    "    bpc = avg_loss / np.log(2)\n",
    "    improv_ratio = V / ppl\n",
    "    delta_nats = lnV - avg_loss\n",
    "\n",
    "    print(\n",
    "        f\"epoch {epoch:03d} \"\n",
    "        f\"train {loss.item():.4f} \"\n",
    "        f\"val_loss {avg_loss:.4f}  ppl {ppl:.0f}  \"\n",
    "        f\"bpc {bpc:.3f}  Δnats {delta_nats:.3f}  x-better {improv_ratio:.2f}x  (lnV {lnV:.3f})\"\n",
    "    )"
   ],
   "id": "96a0a357ebe63e92",
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 15.45 GiB of which 84.44 MiB is free. Including non-PyTorch memory, this process has 15.16 GiB memory in use. Of the allocated memory 14.87 GiB is allocated by PyTorch, and 34.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 14\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# using torch.autocast here with device_type to avoid backend-specific contexts\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mamp\u001B[38;5;241m.\u001B[39mautocast(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m, enabled\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available()):\n\u001B[0;32m---> 14\u001B[0m     logits, loss \u001B[38;5;241m=\u001B[39m model(x, y)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_amp:\n\u001B[1;32m     17\u001B[0m     scaler\u001B[38;5;241m.\u001B[39mscale(loss)\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/dev/miniconda3/envs/music-llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1773\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1774\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1775\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/dev/miniconda3/envs/music-llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1781\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1782\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1783\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1784\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1785\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1786\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1788\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1789\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Documents/dev/music-llm/src/model/model.py:135\u001B[0m, in \u001B[0;36mMusicTransformer.forward\u001B[0;34m(self, idx, targets)\u001B[0m\n\u001B[1;32m    133\u001B[0m     logits \u001B[38;5;241m=\u001B[39m logits\u001B[38;5;241m.\u001B[39mview(B \u001B[38;5;241m*\u001B[39m T, C)  \u001B[38;5;66;03m# perform reshape for cross entropy\u001B[39;00m\n\u001B[1;32m    134\u001B[0m     targets \u001B[38;5;241m=\u001B[39m targets\u001B[38;5;241m.\u001B[39mview(B \u001B[38;5;241m*\u001B[39m T)\n\u001B[0;32m--> 135\u001B[0m     loss \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mcross_entropy(logits, targets)\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m logits, loss\n",
      "File \u001B[0;32m~/dev/miniconda3/envs/music-llm/lib/python3.12/site-packages/torch/nn/functional.py:3458\u001B[0m, in \u001B[0;36mcross_entropy\u001B[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[0m\n\u001B[1;32m   3456\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3457\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[0;32m-> 3458\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_nn\u001B[38;5;241m.\u001B[39mcross_entropy_loss(\n\u001B[1;32m   3459\u001B[0m     \u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m   3460\u001B[0m     target,\n\u001B[1;32m   3461\u001B[0m     weight,\n\u001B[1;32m   3462\u001B[0m     _Reduction\u001B[38;5;241m.\u001B[39mget_enum(reduction),\n\u001B[1;32m   3463\u001B[0m     ignore_index,\n\u001B[1;32m   3464\u001B[0m     label_smoothing,\n\u001B[1;32m   3465\u001B[0m )\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 15.45 GiB of which 84.44 MiB is free. Including non-PyTorch memory, this process has 15.16 GiB memory in use. Of the allocated memory 14.87 GiB is allocated by PyTorch, and 34.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T16:57:35.392217Z",
     "start_time": "2025-10-21T16:57:16.074181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x, y = val_dl.dataset.__getitem__(15)\n",
    "temp = x[:500]\n",
    "out = model.generate(temp.view(1, -1).to(device), max_new_tokens=2500).cpu()\n",
    "out"
   ],
   "id": "f36966a10273d2cf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2258,  456,   23,  ..., 1368,  519,  921]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T16:57:48.279091Z",
     "start_time": "2025-10-21T16:57:48.127879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from miditok import REMI, TokenizerConfig\n",
    "\n",
    "tokenizer = REMI(params=Path(\"../data/tokenized/config/tokenizer.json\"))\n",
    "print(\"Is trained\", tokenizer.is_trained)\n",
    "out_midi = tokenizer.decode(out[0])\n",
    "temp_midi = tokenizer.decode(temp)"
   ],
   "id": "ce320f193e50a6e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is trained True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piffs/dev/miniconda3/envs/music-llm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/piffs/dev/miniconda3/envs/music-llm/lib/python3.12/site-packages/miditok/tokenizations/remi.py:88: UserWarning: Attribute controls are not compatible with 'config.one_token_stream_for_programs' and multi-vocabulary tokenizers. Disabling them from the config.\n",
      "  super().__init__(tokenizer_config, params)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T16:58:21.929887Z",
     "start_time": "2025-10-21T16:58:21.927954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out_midi.dump_midi(data_root / \"output\" / \"test_gen.mid\")\n",
    "temp_midi.dump_midi(data_root / \"output\" / \"input_input.mid\")"
   ],
   "id": "5427de0cbbfbc765",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T18:47:59.227947Z",
     "start_time": "2025-10-20T18:47:59.226240Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d33f2e482dd4afe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fa442dd24e58fcde"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
