{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from src.model.model import MusicTransformer\n",
    "from pathlib import Path\n",
    "\n",
    "from src.utils.data.guitar_dataset import GuitarDataset\n",
    "from src.utils.data.random_guitar_seq_dataset import RandomGuitarSeqDataset\n",
    "from src.utils.hyperparameters import BATCH_SIZE, BLOCK_SIZE, EMBEDDING_DIM, N_LAYER, N_HEAD, DROPOUT, VOCAB_SIZE, \\\n",
    "    LEARNING_RATE"
   ],
   "id": "c487a78f87afdb64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_root = Path(\"../data/\")\n",
    "midi_folder = data_root / \"midi/\"\n",
    "augmented_folder = data_root / \"augmented/\"\n",
    "tokenized_folder = data_root / \"tokenized/\"\n",
    "splits_folder = data_root / \"splits/\"\n",
    "train_tok_folder = tokenized_folder / \"train-aug/\"\n",
    "val_tok_folder = tokenized_folder / \"val/\"\n",
    "train_midi_folder = data_root / \"train-midi/\"\n",
    "val_midi_folder = data_root / \"val-midi/\""
   ],
   "id": "e6ecb80d56c07e23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# hyper-parameters\n",
    "batch_size = BATCH_SIZE\n",
    "\n",
    "block_size = BLOCK_SIZE\n",
    "n_embd = EMBEDDING_DIM\n",
    "vocab_size = VOCAB_SIZE\n",
    "n_layer = N_LAYER\n",
    "n_head = N_HEAD\n",
    "dropout = DROPOUT\n",
    "\n",
    "learning_rate = LEARNING_RATE\n",
    "training_split = 0.8"
   ],
   "id": "d0fd759dece2cc7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# setting the device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ],
   "id": "d313176f924b1e79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# AMP setup, works only on CUDA\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "use_amp = (device.type == \"cuda\")\n",
    "if use_amp and hasattr(torch.cuda,\"is_bf16_supported\") and torch.cuda.is_bf16_supported():\n",
    "    amp_dtype = torch.bfloat16\n",
    "else:\n",
    "    amp_dtype = torch.float16"
   ],
   "id": "d4cf2e30dd1e49ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(hasattr(torch.cuda,\"is_bf16_supported\"))\n",
    "print(torch.cuda.is_bf16_supported())\n",
    "print(use_amp)\n",
    "print(device.type == \"cuda\")\n",
    "device"
   ],
   "id": "af33883b59146db2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Using device\", device)\n",
    "print(\"amp dtype\", amp_dtype)\n",
    "print(\"Torch version\", torch.__version__)"
   ],
   "id": "1a2558d82cc0a417",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# prepare datasets\n",
    "train_files = sorted(train_tok_folder.glob(\"*.json\"))\n",
    "val_files = sorted(val_tok_folder.glob(\"*.json\"))\n",
    "random.shuffle(train_files)\n",
    "\n",
    "# train_ds = GuitarDataset(block_size=block_size, stride=block_size // 2, file_list=train_files)\n",
    "# val_ds = GuitarDataset(block_size=block_size, stride=block_size // 2, file_list=val_files)\n",
    "train_ds = RandomGuitarSeqDataset(block_size=block_size, epoch_len=2000, file_list=train_files)\n",
    "val_ds = RandomGuitarSeqDataset(block_size=block_size,  epoch_len=400, file_list=val_files)"
   ],
   "id": "4e085618437ba1ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, drop_last=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=32, shuffle=True, drop_last=True)"
   ],
   "id": "539692115b123607",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Training tokens count\", train_dl.dataset.total_tokens)\n",
    "print(\"Validation tokens count\", val_dl.dataset.total_tokens)"
   ],
   "id": "776c5472bebd0228",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = MusicTransformer(\n",
    "    vocab_size=vocab_size,\n",
    "    n_embd=n_embd,\n",
    "    n_head=n_head,\n",
    "    n_layer=n_layer,\n",
    "    block_size=block_size,\n",
    "    dropout=dropout\n",
    ").to(device)"
   ],
   "id": "8818a8d2bd225435",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# using AdamW optimisation\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, betas=(0.9, 0.95), weight_decay=0.1)"
   ],
   "id": "c3eb0eca5ba98d83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Parameter count: \", sum([p.numel() for p in model.parameters()]))\n",
    "print(\"Training on \", device)\n",
    "print(\"Using amp?\", use_amp, amp_dtype)"
   ],
   "id": "e69095cfa2232d0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# from src.model.model import Head\n",
    "# import numpy as np\n",
    "# x_test, y_test = train_ds.__getitem__(56)\n",
    "# x_test, y_test = x_test.view(1,-1).to(device), y_test.view(1,-1).to(device)\n",
    "#\n",
    "print(-np.log(1/8000))\n",
    "device\n",
    "#\n",
    "# logits, loss = model(x_test, y_test)\n",
    "# loss"
   ],
   "id": "781977d0ce522c2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "scaler = torch.amp.GradScaler('cuda', enabled=(use_amp and amp_dtype == torch.float16))",
   "id": "572c9dcebbf3f157",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "epochs = 20\n",
    "V = vocab_size\n",
    "lnV = np.log(V)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ---- train -----\n",
    "    model.train()\n",
    "    for x, y in train_dl:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # using torch.autocast here with device_type to avoid backend-specific contexts\n",
    "        with torch.amp.autocast('cuda', dtype=amp_dtype, enabled=torch.cuda.is_available()):\n",
    "            logits, loss = model(x, y)\n",
    "\n",
    "        if use_amp and amp_dtype == torch.float16:\n",
    "            # FP16 path: scale, unscale before clipping, then step\n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            # BF16 path\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "    # ----- validate -----\n",
    "    model.eval()\n",
    "    val_loss, total_tokens = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        # also using AMP in eval to cut memory/latency\n",
    "        with torch.amp.autocast('cuda',dtype=amp_dtype, enabled=use_amp):\n",
    "            for x, y in val_dl:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                _, l = model(x, y) # loss here is already mean loss per token for this batch\n",
    "                # as we have already reshaped logits in forward when computing loss against targets\n",
    "                num_tokens = y.numel()\n",
    "                val_loss += l.item() * num_tokens\n",
    "                total_tokens += num_tokens\n",
    "\n",
    "    avg_loss = val_loss / total_tokens\n",
    "    ppl = np.exp(avg_loss)\n",
    "    bpc = avg_loss / np.log(2)\n",
    "    improv_ratio = V / ppl\n",
    "    delta_nats = lnV - avg_loss\n",
    "\n",
    "    print(\n",
    "        f\"epoch {epoch:03d} \"\n",
    "        f\"train {loss.item():.4f} \"\n",
    "        f\"val_loss {avg_loss:.4f}  ppl {ppl:.0f}  \"\n",
    "        f\"bpc {bpc:.3f}  Î”nats {delta_nats:.3f}  x-better {improv_ratio:.2f}x  (lnV {lnV:.3f})\"\n",
    "    )"
   ],
   "id": "96a0a357ebe63e92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x, y = val_dl.dataset.__getitem__(15)\n",
    "temp = x[:500]\n",
    "out = model.generate(temp.view(1, -1).to(device), max_new_tokens=2500).cpu()\n",
    "out"
   ],
   "id": "f36966a10273d2cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from miditok import REMI, TokenizerConfig\n",
    "\n",
    "tokenizer = REMI(params=Path(\"../data/tokenized/config/tokenizer.json\"))\n",
    "print(\"Is trained\", tokenizer.is_trained)\n",
    "out_midi = tokenizer.decode(out[0])\n",
    "temp_midi = tokenizer.decode(temp)"
   ],
   "id": "ce320f193e50a6e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "out_midi.dump_midi(data_root / \"output\" / \"test_gen.mid\")\n",
    "temp_midi.dump_midi(data_root / \"output\" / \"input_input.mid\")"
   ],
   "id": "5427de0cbbfbc765",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d33f2e482dd4afe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fa442dd24e58fcde",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
