{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-12T18:25:42.445509Z",
     "start_time": "2025-09-12T18:25:41.890229Z"
    }
   },
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from src.model.model import MusicTransformer\n",
    "from pathlib import Path\n",
    "\n",
    "from src.utils.create_dataset import GuitarDataset\n",
    "from src.utils.hyperparameters import BATCH_SIZE, BLOCK_SIZE, EMBEDDING_DIM, N_LAYER, N_HEAD, DROPOUT, VOCAB_SIZE, \\\n",
    "    LEARNING_RATE"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T18:25:42.449312Z",
     "start_time": "2025-09-12T18:25:42.447859Z"
    }
   },
   "cell_type": "code",
   "source": "tokenized_folder = Path(\"../data/tokenized/\")",
   "id": "2c615b49338f37ba",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T18:25:42.507632Z",
     "start_time": "2025-09-12T18:25:42.505659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# hyper-parameters\n",
    "batch_size = BATCH_SIZE\n",
    "\n",
    "block_size = BLOCK_SIZE\n",
    "n_embd = EMBEDDING_DIM\n",
    "vocab_size = VOCAB_SIZE\n",
    "n_layer = N_LAYER\n",
    "n_head = N_HEAD\n",
    "dropout = DROPOUT\n",
    "\n",
    "learning_rate = LEARNING_RATE\n",
    "training_split = 0.8"
   ],
   "id": "d0fd759dece2cc7e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T18:25:42.522261Z",
     "start_time": "2025-09-12T18:25:42.511121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# setting the device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ],
   "id": "d313176f924b1e79",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T18:25:42.526925Z",
     "start_time": "2025-09-12T18:25:42.525392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# AMP setup, works only on CUDA\n",
    "use_amp = (device == \"cuda\")\n",
    "if use_amp and hasattr(torch.cuda, \"is_bf16_supported\") and torch.cuda.is_bf16_supported():\n",
    "    amp_dtype = torch.bfloat16\n",
    "else:\n",
    "    amp_dtype = torch.float16\n",
    "\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=use_amp)"
   ],
   "id": "d4cf2e30dd1e49ce",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T18:25:42.540897Z",
     "start_time": "2025-09-12T18:25:42.530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# prepare datasets\n",
    "all_files = sorted(tokenized_folder.glob(\"*.json\"))\n",
    "random.shuffle(all_files)\n",
    "\n",
    "split = int(training_split * len(all_files))\n",
    "train_ds = GuitarDataset(block_size=block_size, stride=block_size // 2, file_list=all_files[:split])\n",
    "val_ds = GuitarDataset(block_size=block_size, stride=block_size // 2, file_list=all_files[split:])"
   ],
   "id": "4e085618437ba1ad",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T18:25:42.545325Z",
     "start_time": "2025-09-12T18:25:42.543983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, drop_last=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=32, shuffle=True, drop_last=True)"
   ],
   "id": "539692115b123607",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T18:25:42.549824Z",
     "start_time": "2025-09-12T18:25:42.548326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Training tokens count\", train_dl.dataset.tokens)\n",
    "print(\"Validation tokens count\", val_dl.dataset.tokens)"
   ],
   "id": "776c5472bebd0228",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens count 56874\n",
      "Validation tokens count 11013\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T18:25:42.603832Z",
     "start_time": "2025-09-12T18:25:42.553488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = MusicTransformer(\n",
    "    vocab_size=vocab_size,\n",
    "    n_embd=n_embd,\n",
    "    n_head=n_head,\n",
    "    n_layer=n_layer,\n",
    "    block_size=block_size,\n",
    "    dropout=dropout\n",
    ").to(device)"
   ],
   "id": "8818a8d2bd225435",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T18:25:43.131495Z",
     "start_time": "2025-09-12T18:25:42.608181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# using AdamW optimisation\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, betas=(0.9, 0.95), weight_decay=0.1)"
   ],
   "id": "c3eb0eca5ba98d83",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T18:25:43.136814Z",
     "start_time": "2025-09-12T18:25:43.135073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Parameter count: \", sum([p.numel() for p in model.parameters()]))\n",
    "print(\"Training on \", device)\n",
    "print(\"Using amp?\", use_amp)"
   ],
   "id": "e69095cfa2232d0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter count:  7293248\n",
      "Training on  mps\n",
      "Using amp? False\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T18:25:43.146212Z",
     "start_time": "2025-09-12T18:25:43.144911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from src.model.model import Head\n",
    "# import numpy as np\n",
    "# x_test, y_test = train_ds.__getitem__(56)\n",
    "# x_test, y_test = x_test.view(1,-1).to(device), y_test.view(1,-1).to(device)\n",
    "#\n",
    "# print(-np.log(1/8000))\n",
    "#\n",
    "# logits, loss = model(x_test, y_test)\n",
    "# loss"
   ],
   "id": "781977d0ce522c2e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T18:26:43.244345Z",
     "start_time": "2025-09-12T18:25:43.153847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 40\n",
    "for epoch in range(epochs):\n",
    "    # ---- train -----\n",
    "    model.train()\n",
    "    for x, y in train_dl:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # using torch.autocast here with device_type to avoid backend-specific contexts\n",
    "        with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
    "            logits, loss = model(x, y)\n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "    # ----- validate -----\n",
    "    model.eval()\n",
    "    val_loss, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_dl:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            _, l = model(x, y)\n",
    "            val_loss += l.item() * x.size(0)\n",
    "            n += x.size(0)\n",
    "    print(f\"echo {epoch:03d} train {loss.item():.4f} val_loss {val_loss / max(n, 1):.4f}\")"
   ],
   "id": "96a0a357ebe63e92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo 000 train 8.3482 val_loss 8.8177\n",
      "echo 001 train 8.0376 val_loss 9.0495\n",
      "echo 002 train 7.9794 val_loss 9.1665\n",
      "echo 003 train 7.7498 val_loss 9.1924\n",
      "echo 004 train 7.5435 val_loss 9.1260\n",
      "echo 005 train 7.2530 val_loss 9.1353\n",
      "echo 006 train 6.9629 val_loss 9.1272\n",
      "echo 007 train 6.6261 val_loss 9.1576\n",
      "echo 008 train 6.4796 val_loss 9.0593\n",
      "echo 009 train 5.9986 val_loss 9.0749\n",
      "echo 010 train 5.8222 val_loss 8.9571\n",
      "echo 011 train 5.4572 val_loss 8.9254\n",
      "echo 012 train 5.4504 val_loss 8.9660\n",
      "echo 013 train 4.9782 val_loss 8.9374\n",
      "echo 014 train 4.7423 val_loss 8.9618\n",
      "echo 015 train 4.6196 val_loss 8.8332\n",
      "echo 016 train 4.2551 val_loss 8.8128\n",
      "echo 017 train 4.1415 val_loss 8.8350\n",
      "echo 018 train 3.9037 val_loss 8.7589\n",
      "echo 019 train 3.8274 val_loss 8.7422\n",
      "echo 020 train 3.4322 val_loss 8.8496\n",
      "echo 021 train 3.1950 val_loss 8.7374\n",
      "echo 022 train 3.1859 val_loss 8.7140\n",
      "echo 023 train 2.7347 val_loss 8.8068\n",
      "echo 024 train 2.6953 val_loss 8.7132\n",
      "echo 025 train 2.6162 val_loss 8.8279\n",
      "echo 026 train 2.4962 val_loss 8.8560\n",
      "echo 027 train 2.1637 val_loss 8.6830\n",
      "echo 028 train 2.3057 val_loss 8.6942\n",
      "echo 029 train 2.1337 val_loss 8.7876\n",
      "echo 030 train 1.7387 val_loss 8.7106\n",
      "echo 031 train 1.8106 val_loss 8.8715\n",
      "echo 032 train 1.8059 val_loss 8.7780\n",
      "echo 033 train 1.6548 val_loss 8.7102\n",
      "echo 034 train 1.4776 val_loss 8.8551\n",
      "echo 035 train 1.4348 val_loss 8.8433\n",
      "echo 036 train 1.2297 val_loss 8.8550\n",
      "echo 037 train 1.2708 val_loss 8.8639\n",
      "echo 038 train 1.1302 val_loss 8.7869\n",
      "echo 039 train 1.0645 val_loss 8.8950\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T18:29:34.420204Z",
     "start_time": "2025-09-12T18:29:31.825290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x, y = val_dl.dataset.__getitem__(5)\n",
    "temp = x[:50]\n",
    "out = model.generate(temp.view(1, -1).to(device), max_new_tokens=100).cpu()\n",
    "out"
   ],
   "id": "f36966a10273d2cf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 446, 2392, 3269,   45, 3049,   43,  658, 6527, 4100, 3049, 7612, 7613,\n",
       "          704,   38,  106,  120, 2490, 1646, 2097,  658, 2041, 2399, 7692, 7698,\n",
       "          496, 6527, 5731, 3049,   47, 6148, 2182,  704,   45, 1646,  283, 2490,\n",
       "         1646, 2097,  658, 2041, 2399, 7692, 7698,  496, 6527, 4100, 3049, 7612,\n",
       "         7613, 1523, 3250, 5876, 3588, 3738,   35, 1659, 6171, 5164, 3049,   47,\n",
       "         1211,   61,  107, 7671, 3189,  555, 2093,  681, 2273,  581, 3900, 4932,\n",
       "         7607, 3900, 4932, 7607, 6150, 1896, 1868, 4989, 4802, 3680, 6016, 3755,\n",
       "         7513, 2017, 1447, 3865, 7866, 7875,   52,  635, 7728, 4347, 4910, 3409,\n",
       "           69,  642,  486, 1699, 2475,   32, 2105, 2251,   42, 7903, 5157, 4114,\n",
       "           30, 2477,   47,  496, 2678,  111,  493,   66,  623, 1420,   31,  681,\n",
       "         1494, 6081, 3605, 1030, 7308, 1422,  296, 6889, 2459,  995,   37,  544,\n",
       "          463,   15, 1047,  970, 5795,  466, 3461, 5493,  484,  623, 1912,  919,\n",
       "          995, 1572, 4394, 6196,  453, 1990]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ce320f193e50a6e5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
